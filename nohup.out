Using tensorboardX
Fix size testing.
training chunk_sizes: [5]
The output will be saved to  /home/fatih/phd/FairMOT/src/lib/../../exp/mot/data_all_dla34_gtx1080ti
Setting up data...
================================================================================
dataset summary
OrderedDict([('mot17', 1582.0), ('caltech', 1043.0), ('citypersons', 0), ('cuhksysu', 11931.0), ('prw', 933.0), ('eth', 0), ('crowdhuman_train', 339565.0), ('crowdhuman_val', 99481.0)])
total # identities: 454536
start index
OrderedDict([('mot17', 0), ('caltech', 1582.0), ('citypersons', 2625.0), ('cuhksysu', 2625.0), ('prw', 14556.0), ('eth', 15489.0), ('crowdhuman_train', 15489.0), ('crowdhuman_val', 355054.0)])
================================================================================
heads {'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}
Namespace(task='mot', dataset='jde', exp_id='data_all_dla34_gtx1080ti', test=False, load_model='../models/ctdet_coco_dla_2x.pth', resume=False, gpus=[0], num_workers=8, not_cuda_benchmark=False, seed=317, print_iter=0, hide_data_time=False, save_all=False, metric='loss', vis_thresh=0.5, arch='dla_34', head_conv=256, down_ratio=4, input_res=1088, input_h=1088, input_w=608, lr=0.0005, lr_step=[20], num_epochs=30, batch_size=5, master_batch_size=5, num_iters=-1, val_intervals=5, trainval=False, K=500, not_prefetch_test=False, fix_res=True, keep_res=False, test_mot16=False, val_mot15=False, test_mot15=False, val_mot16=False, test_mot17=False, val_mot17=True, val_mot20=False, test_mot20=False, val_hie=False, test_hie=False, conf_thres=0.4, det_thres=0.3, nms_thres=0.4, track_buffer=30, min_box_area=100, input_video='../videos/MOT16-03.mp4', output_format='video', output_root='../demos', data_cfg='../src/lib/cfg/data_all.json', data_dir='/home/zyf/dataset', mse_loss=False, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, id_loss='ce', id_weight=1, reid_dim=128, ltrb=True, multi_loss='uncertainty', norm_wh=False, dense_wh=False, cat_spec_wh=False, not_reg_offset=False, gpus_str='0', reg_offset=True, pad=31, num_stacks=1, chunk_sizes=[5], root_dir='/home/fatih/phd/FairMOT/src/lib/../..', exp_dir='/home/fatih/phd/FairMOT/src/lib/../../exp/mot', save_dir='/home/fatih/phd/FairMOT/src/lib/../../exp/mot/data_all_dla34_gtx1080ti', debug_dir='/home/fatih/phd/FairMOT/src/lib/../../exp/mot/data_all_dla34_gtx1080ti/debug', mean=None, std=None, num_classes=1, output_h=272, output_w=152, output_res=272, heads={'hm': 1, 'wh': 4, 'id': 128, 'reg': 2}, nID=454536, img_size=(1088, 608))
0
Creating model...
Starting training...
loaded ../models/ctdet_coco_dla_2x.pth, epoch 230
Skip loading parameter hm.2.weight, required shapetorch.Size([1, 256, 1, 1]), loaded shapetorch.Size([80, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.
Skip loading parameter hm.2.bias, required shapetorch.Size([1]), loaded shapetorch.Size([80]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.
Skip loading parameter wh.2.weight, required shapetorch.Size([4, 256, 1, 1]), loaded shapetorch.Size([2, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.
Skip loading parameter wh.2.bias, required shapetorch.Size([4]), loaded shapetorch.Size([2]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.
No param id.0.weight.If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.
No param id.0.bias.If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.
No param id.2.weight.If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.
No param id.2.bias.If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.
/home/fatih/miniconda3/envs/fairmot-x/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Traceback (most recent call last):
  File "/home/fatih/phd/FairMOT/src/train.py", line 97, in <module>
    main(opt)
  File "/home/fatih/phd/FairMOT/src/train.py", line 69, in main
    log_dict_train, _ = trainer.train(epoch, train_loader)
  File "/home/fatih/phd/FairMOT/src/lib/trains/base_trainer.py", line 119, in train
    return self.run_epoch('train', epoch, data_loader)
  File "/home/fatih/phd/FairMOT/src/lib/trains/base_trainer.py", line 85, in run_epoch
    loss_stats[l].mean().item(), batch['input'].size(0))
KeyboardInterrupt
